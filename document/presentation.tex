\documentclass[aspectratio=169,dvipdfmx,unicode]{beamer}

% テーマ設定
\usetheme{Madrid}
\usecolortheme{default}
\usefonttheme{professionalfonts}

% 日本語設定（upLaTeX用）- 明朝体
\usepackage{pxjahyper}
\usepackage{minijs}
\renewcommand{\kanjifamilydefault}{\mcdefault}

% 英字フォント設定（Times系）- Beamer標準のserifフォントを使用
\usefonttheme{serif}

% パッケージ
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{url}

% 画像が存在しない場合のダミー設定
\usepackage{ifthen}
\newcommand{\includefigure}[2][width=\textwidth]{%
  \IfFileExists{#2}{%
    \includegraphics[#1]{#2}%
  }{%
    \fbox{\parbox{0.8\textwidth}{\centering\vspace{1cm}[画像未生成]\vspace{1cm}}}%
  }%
}

% タイトル情報
\title{オーストラリア天気予測}
\subtitle{明日の雨予測モデルの構築と比較}
\author{}
\date{\today}
\institute{}

% カスタマイズ
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{footline}[frame number]

\begin{document}

%============================================
% スライド1: タイトル
%============================================
\begin{frame}
    \titlepage
\end{frame}

%============================================
% セクション1: 課題概要
%============================================
\section{課題概要}

%============================================
% スライド2: 課題の背景・テーマ選定理由
%============================================
\begin{frame}{課題の背景}
    \begin{block}{目的}
        オーストラリアの気象データを用いて、\textbf{明日が雨になるか否か}を予測する2値分類モデルを構築する
    \end{block}

    \vspace{0.3cm}

    \textbf{なぜこのテーマを選んだか}
    \begin{itemize}
        \item 金沢市は年間降水量が多く、雨の日を事前に予測できると日常生活で役立つ
        \item 気象データを用いた機械学習予測に興味があった
        \item 2値分類の実践的な題材として適切だった
    \end{itemize}

    \vspace{0.3cm}

    \textbf{日常生活・研究への応用}
    \begin{itemize}
        \item 外出・イベントの計画立案
        \item 農業における作業スケジュール管理
        \item 交通機関の運行計画への活用
    \end{itemize}
\end{frame}

%============================================
% スライド3: データセット概要
%============================================
\begin{frame}{データセット概要}
    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \textbf{基本情報}
            \begin{itemize}
                \item レコード数: 145,460件
                \item 特徴量数: 23カラム
                \item ターゲット: RainTomorrow (Yes/No)
                \item 期間: 2007年11月〜2017年6月
                \item 観測地点: オーストラリア全土49箇所
            \end{itemize}

            \vspace{0.3cm}

            \textbf{クラス分布（不均衡）}
            \begin{itemize}
                \item No（雨なし）: 78\%
                \item Yes（雨あり）: 22\%
            \end{itemize}

            \vspace{0.2cm}
            {\small 出典: Young, J. (2017). Rain in Australia. Kaggle Dataset.\\
            \url{https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package}}
        \end{column}

        \begin{column}{0.5\textwidth}
            \begin{figure}
                \centering
                \includefigure[width=\textwidth]{figures/target_distribution.png}
                \caption{ターゲット変数の分布}
            \end{figure}
        \end{column}
    \end{columns}
\end{frame}

%============================================
% セクション2: データ分析
%============================================
\section{データ分析}

%============================================
% スライド4: 特徴量の種類
%============================================
\begin{frame}{特徴量の種類}
    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \textbf{数値変数（16個）}
            \begin{itemize}
                \item 気温: MinTemp, MaxTemp, Temp9am, Temp3pm
                \item 降水: Rainfall, Evaporation
                \item 日照: Sunshine
                \item 風速: WindGustSpeed, WindSpeed9am/3pm
                \item 湿度: Humidity9am/3pm
                \item 気圧: Pressure9am/3pm
                \item 雲量: Cloud9am/3pm
            \end{itemize}
        \end{column}

        \begin{column}{0.5\textwidth}
            \textbf{カテゴリ変数（6個）}
            \begin{itemize}
                \item Location: 49観測地点
                \item WindGustDir: 突風方向（16方位）
                \item WindDir9am: 9時の風向
                \item WindDir3pm: 15時の風向
                \item RainToday: 本日の雨（Yes/No）
                \item \textbf{RainTomorrow}: ターゲット
            \end{itemize}
        \end{column}
    \end{columns}
\end{frame}

%============================================
% セクション3: 前処理
%============================================
\section{前処理}

%============================================
% スライド5: データ分割
%============================================
\begin{frame}{データ分割（時系列）}
    \begin{block}{時系列分割の重要性}
        未来のデータで過去を予測することを防ぐため、\textbf{時間順序を保持}してデータを分割
    \end{block}

    \vspace{0.5cm}

    \begin{table}[h]
        \centering
        \begin{tabular}{lccc}
            \toprule
            データセット & 期間 & レコード数 & 割合 \\
            \midrule
            Train & 〜2015/06 & 約113,000 & 80\% \\
            Validation & 2015/07〜2016/06 & 約14,000 & 10\% \\
            Test & 2016/07〜 & 約14,000 & 10\% \\
            \bottomrule
        \end{tabular}
    \end{table}
\end{frame}

%============================================
% スライド6: 前処理の詳細
%============================================
\begin{frame}{前処理の詳細}
    \textbf{1. 欠損値処理}
    \begin{itemize}
        \item 数値変数: Location別の中央値で補完
        \item カテゴリ変数: Location別の最頻値で補完
        \item RainTomorrow欠損行は削除
    \end{itemize}

    \vspace{0.3cm}

    \textbf{2. 特徴量エンコーディング}
    \begin{itemize}
        \item 風向（16方位）: サイクリカルエンコーディング（$\sin\theta$, $\cos\theta$）
        \item RainToday: バイナリ（Yes=1, No=0）
        \item Location: ラベルエンコーディング
    \end{itemize}

    \vspace{0.3cm}

    \textbf{3. 標準化}
    \begin{itemize}
        \item StandardScaler（平均0、標準偏差1）
        \item Trainデータで学習し、Val/Testに適用
    \end{itemize}
\end{frame}

%============================================
% セクション4: モデル実装
%============================================
\section{モデル実装}

%============================================
% スライド7: 使用モデル
%============================================
\begin{frame}{使用モデル}
    \begin{enumerate}
        \item \textbf{ロジスティック回帰}（PyTorch実装）
        \begin{itemize}
            \item 構造: 入力層 → 出力層（1ユニット）のシンプルな線形モデル
            \item 特長: 解釈性が高く、各特徴量の重みから予測への寄与度がわかる
            \item 用途: ベースラインモデルとして使用
        \end{itemize}

        \vspace{0.3cm}

        \item \textbf{MLP（Multi-Layer Perceptron）}（PyTorch実装）
        \begin{itemize}
            \item 構造: 入力層 → 隠れ層（複数）→ 出力層の多層ニューラルネット
            \item 特長: 非線形な関係を学習可能、BatchNormとDropoutで過学習を抑制
            \item 用途: より複雑なパターンの学習
        \end{itemize}

        \vspace{0.3cm}

        \item \textbf{Random Forest}（scikit-learn）
        \begin{itemize}
            \item 構造: 複数の決定木を並列に学習し、多数決で予測するアンサンブル手法
            \item 特長: 過学習に強く、特徴量重要度を算出可能
            \item 用途: 非線形関係の効果的な捕捉
        \end{itemize}
    \end{enumerate}
\end{frame}

%============================================
% スライド8: クラス不均衡対策
%============================================
\begin{frame}{クラス不均衡対策}
    \begin{block}{問題点}
        Yes:No = 22:78 の不均衡データでは、「すべてNoと予測」しても78\%の精度になってしまう
    \end{block}

    \vspace{0.3cm}

    \textbf{実施した対策}

    \vspace{0.2cm}

    \begin{enumerate}
        \item \textbf{ロジスティック回帰・MLP}（PyTorchモデル）
        \begin{itemize}
            \item 損失関数に重み付けを導入（Weighted BCE Loss）
            \item 少数クラス（雨あり）の誤分類に対するペナルティを大きく設定
            \item 重み比率: No:Yes = 1:3.5（クラス比率の逆数）
        \end{itemize}

        \vspace{0.2cm}

        \item \textbf{Random Forest}（scikit-learn）
        \begin{itemize}
            \item class\_weight='balanced' パラメータを使用
            \item 各クラスのサンプル数に応じて自動的に重みを調整
        \end{itemize}
    \end{enumerate}

    \vspace{0.3cm}

    これらの対策により、少数クラス（雨あり）の検出率を向上させた
\end{frame}

%============================================
% セクション5: ハイパーパラメータチューニング
%============================================
\section{ハイパーパラメータチューニング}

%============================================
% スライド9: ロジスティック回帰のチューニング
%============================================
\begin{frame}{ロジスティック回帰のチューニング}
    \textbf{探索したハイパーパラメータ}
    \begin{itemize}
        \item 学習率: モデルの重み更新の大きさを制御するパラメータ
        \item 重み減衰（L2正則化）: 過学習を防ぐための正則化強度
        \item オプティマイザ: 最適化アルゴリズム（SGD, Adam）
        \item 損失関数: Weighted BCE Loss
    \end{itemize}

    \vspace{0.3cm}

    \begin{figure}
        \centering
        \includefigure[width=0.6\textwidth]{figures/learning_curves/logistic_regression.png}
        \caption{ロジスティック回帰の学習曲線（エポックごとの損失とAccuracyの推移）}
    \end{figure}
\end{frame}

%============================================
% スライド10: MLPのチューニング
%============================================
\begin{frame}{MLPのチューニング}
    \textbf{探索したハイパーパラメータ}
    \begin{itemize}
        \item 隠れ層数・ユニット数: ネットワークの深さと幅
        \item Dropout率: 過学習防止のためのドロップアウト確率
        \item 学習率・重み減衰: ロジスティック回帰と同様
        \item オプティマイザ: Adam, AdamW
    \end{itemize}

    \vspace{0.3cm}

    \begin{figure}
        \centering
        \includefigure[width=0.6\textwidth]{figures/learning_curves/mlp.png}
        \caption{MLPの学習曲線（エポックごとの損失とAccuracyの推移）}
    \end{figure}
\end{frame}

%============================================
% スライド11: Random Forestのチューニング
%============================================
\begin{frame}{Random Forestのチューニング}
    \textbf{探索したハイパーパラメータ}
    \begin{itemize}
        \item n\_estimators: 決定木の数（多いほど安定するが計算コスト増）
        \item max\_depth: 各決定木の最大深さ（深いほど複雑なパターンを学習）
        \item min\_samples\_split: ノード分割に必要な最小サンプル数
        \item min\_samples\_leaf: 葉ノードに必要な最小サンプル数
        \item max\_features: 各分割で考慮する特徴量の数
    \end{itemize}

    \vspace{0.3cm}

    Random Forestは決定木のアンサンブルであり、学習曲線ではなく上記パラメータの組み合わせを探索して最適なモデルを選定した
\end{frame}

%============================================
% セクション6: 結果
%============================================
\section{実験結果}

%============================================
% スライド12: 評価指標
%============================================
\begin{frame}{評価指標}
    \begin{table}[h]
        \centering
        \begin{tabular}{lp{9cm}}
            \toprule
            指標 & 説明 \\
            \midrule
            Accuracy & 全体の正解率。全予測のうち正しく分類できた割合 \\
            \midrule
            Precision & 「雨」と予測したもののうち、実際に雨だった割合。誤警報を減らしたい場合に重視 \\
            \midrule
            Recall & 実際の雨の日のうち、正しく「雨」と予測できた割合。見逃しを減らしたい場合に重視 \\
            \midrule
            F1-Score & PrecisionとRecallの調和平均。両者のバランスを評価 \\
            \bottomrule
        \end{tabular}
    \end{table}

    \vspace{0.3cm}

    \begin{block}{不均衡データでの注意点}
        Accuracyだけでは正しく評価できない。Precision, Recall, F1-Scoreを総合的に見ることが重要
    \end{block}
\end{frame}

%============================================
% スライド13: テストデータでの評価結果
%============================================
\begin{frame}{テストデータでの評価結果}
    \begin{table}[h]
        \centering
        \begin{tabular}{lcccc}
            \toprule
            モデル & Accuracy & Precision & Recall & F1-Score \\
            \midrule
            ロジスティック回帰 & 0.785 & 0.526 & 0.742 & 0.616 \\
            MLP & 0.797 & 0.542 & 0.785 & 0.641 \\
            \textbf{Random Forest} & \textbf{0.843} & \textbf{0.764} & 0.463 & 0.577 \\
            \bottomrule
        \end{tabular}
        \caption{各モデルの評価指標（テストデータ）}
    \end{table}

    \vspace{0.3cm}

    \textbf{結果の概要}
    \begin{itemize}
        \item Random ForestがAccuracyとPrecisionで最高
        \item MLPがRecallとF1-Scoreで最高
        \item ロジスティック回帰はベースラインとして妥当な性能
    \end{itemize}
\end{frame}

%============================================
% スライド14: 混同行列
%============================================
\begin{frame}{混同行列}
    \begin{figure}
        \centering
        \includefigure[width=0.85\textwidth]{figures/confusion_matrices/comparison.png}
        \caption{各モデルの混同行列}
    \end{figure}
\end{frame}

%============================================
% セクション7: 考察
%============================================
\section{考察}

%============================================
% スライド15: モデル比較の考察
%============================================
\begin{frame}{モデル比較の考察}
    \textbf{Random Forestの高いAccuracy・Precisionの理由}
    \begin{itemize}
        \item 決定木のアンサンブルにより、特徴量間の複雑な相互作用を捉えられた
        \item 気象データは非線形な関係が多く、木構造との相性が良かった
        \item ただしRecallが低く、雨の日の見逃しが多い
    \end{itemize}

    \vspace{0.3cm}

    \textbf{MLPの高いRecall・F1-Scoreの理由}
    \begin{itemize}
        \item 重み付き損失関数により、少数クラス（雨あり）を積極的に検出
        \item 多層構造により非線形パターンを学習できた
        \item Precisionは低めで、誤警報が多い傾向
    \end{itemize}

    \vspace{0.3cm}

    \textbf{ロジスティック回帰の限界}
    \begin{itemize}
        \item 線形モデルのため、非線形な関係の捕捉に限界がある
        \item しかしベースラインとして、他モデルの改善度を測る基準になった
    \end{itemize}
\end{frame}

%============================================
% スライド16: 重要な特徴量
%============================================
\begin{frame}{重要な特徴量}
    Random Forestの特徴量重要度分析から:

    \vspace{0.2cm}

    \begin{columns}[T]
        \begin{column}{0.5\textwidth}
            \textbf{上位の特徴量}
            \begin{enumerate}
                \item \textbf{Humidity3pm}: 午後の湿度
                \item \textbf{Pressure3pm}: 午後の気圧
                \item \textbf{Sunshine}: 日照時間
                \item \textbf{Cloud3pm}: 午後の雲量
                \item \textbf{RainToday}: 本日の雨の有無
            \end{enumerate}

            \vspace{0.3cm}

            \begin{block}{気象学的解釈}
                午後の湿度・気圧・雲量は、翌日の降雨を予測する上で物理的に妥当な指標
            \end{block}
        \end{column}

        \begin{column}{0.5\textwidth}
            \begin{figure}
                \centering
                \includefigure[width=\textwidth]{figures/feature_importance/random_forest.png}
                \caption{特徴量重要度（上位10）}
            \end{figure}
        \end{column}
    \end{columns}
\end{frame}

%============================================
% セクション8: まとめ
%============================================
\section{まとめ}

%============================================
% スライド17: まとめ
%============================================
\begin{frame}{まとめ}
    \textbf{本研究の成果}
    \begin{enumerate}
        \item 3種類のモデル（ロジスティック回帰、MLP、Random Forest）を実装・比較
        \item 体系的なハイパーパラメータチューニングを実施
        \item クラス不均衡に対する適切な対策（重み付き損失関数）を適用
        \item Random ForestがAccuracy 0.843、Precision 0.764で最高性能を達成
    \end{enumerate}

    \vspace{0.5cm}

    \textbf{今後の課題}
    \begin{itemize}
        \item 勾配ブースティング（LightGBM、XGBoost）の追加検討
        \item 時系列特徴量（ラグ特徴量、移動平均）の導入
        \item Recallを重視したモデル調整（雨の見逃しを減らす）
    \end{itemize}
\end{frame}

\end{document}
